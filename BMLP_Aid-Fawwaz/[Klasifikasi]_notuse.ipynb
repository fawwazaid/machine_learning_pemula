{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvAKGat01Sd",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Penting**\n",
    "- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.\n",
    "- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.\n",
    "- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.\n",
    "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
    "- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.\n",
    "- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan\n",
    "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan\n",
    "- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **1. Import Library**\n",
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "#Type your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **2. Memuat Dataset dari Hasil Clustering**\n",
    "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "# Gunakan dataset hasil clustering yang memiliki fitur Target\n",
    "# Silakan gunakan dataset data_clustering jika tidak menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "# Silakan gunakan dataset data_clustering_inverse jika menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "# Lengkapi kode berikut\n",
    "# ___ = pd_read_csv(\"___.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCsep0NZ0LUf"
   },
   "outputs": [],
   "source": [
    "# Tampilkan 5 baris pertama dengan function head.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkPem5eWL2UP"
   },
   "source": [
    "# **3. Data Splitting**\n",
    "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OubAW-7ONKVj"
   },
   "outputs": [],
   "source": [
    "# Menggunakan train_test_split() untuk melakukan pembagian dataset.\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = data.drop(columns=['Exited'])\n",
    "y = data['Exited']\n",
    " \n",
    "# Split data menjadi set pelatihan dan set uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split\n",
    "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVPbB03CMhTT"
   },
   "source": [
    "# **4. Membangun Model Klasifikasi**\n",
    "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
    "\n",
    "Berikut adalah rekomendasi tahapannya.\n",
    "1. Menggunakan algoritma klasifikasi yaitu Decision Tree.\n",
    "2. Latih model menggunakan data yang sudah dipisah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JYxBe87NLDk"
   },
   "outputs": [],
   "source": [
    "# Buatlah model klasifikasi menggunakan Decision Tree\n",
    "dt = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_AakAxghYv-"
   },
   "outputs": [],
   "source": [
    "# Menyimpan Model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'decision_tree_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **5. Memenuhi Kriteria Skilled dan Advanced dalam Membangun Model Klasifikasi**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNOEZk24uiXu"
   },
   "source": [
    "**Biarkan kosong jika tidak menerapkan kriteria skilled atau advanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB_8LIWMATl6"
   },
   "outputs": [],
   "source": [
    "# Melatih model menggunakan algoritma klasifikasi scikit-learn selain Decision Tree.\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "svm = SVC().fit(X_train, y_train)\n",
    "nb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRlKm5BVAT91"
   },
   "outputs": [],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.\n",
    "# Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    results = {\n",
    "        'Confusion Matrix': cm,\n",
    "        'True Positive (TP)': tp,\n",
    "        'False Positive (FP)': fp,\n",
    "        'False Negative (FN)': fn,\n",
    "        'True Negative (TN)': tn,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    return results\n",
    " \n",
    "# Mengevaluasi setiap model dan mengumpulkan hasilnya\n",
    "results = {\n",
    "    'K-Nearest Neighbors (KNN)': evaluate_model(knn, X_test, y_test),\n",
    "    'Decision Tree (DT)': evaluate_model(dt, X_test, y_test),\n",
    "    'Random Forest (RF)': evaluate_model(rf, X_test, y_test),\n",
    "    'Support Vector Machine (SVM)': evaluate_model(svm, X_test, y_test),\n",
    "    'Naive Bayes (NB)': evaluate_model(nb, X_test, y_test)\n",
    "}\n",
    " \n",
    "# Buat DataFrame untuk meringkas hasil\n",
    "summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    " \n",
    "# Isi DataFrame dengan hasil\n",
    "rows = []\n",
    "for model_name, metrics in results.items():\n",
    "    rows.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['Accuracy'],\n",
    "        'Precision': metrics['Precision'],\n",
    "        'Recall': metrics['Recall'],\n",
    "        'F1-Score': metrics['F1-Score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUPItkbXBNkO"
   },
   "outputs": [],
   "source": [
    "# Menyimpan Model Selain Decision Tree\n",
    "# Model ini bisa lebih dari satu\n",
    "# import joblib\n",
    "# joblib.dump(___, 'explore_<Nama Algoritma>_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u23H2guj-h9h"
   },
   "source": [
    "Hyperparameter Tuning Model\n",
    "\n",
    "Pilih salah satu algoritma yang ingin Anda tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFCTxJJq-m-l"
   },
   "outputs": [],
   "source": [
    "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
    "# Lakukan dalam satu cell ini saja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# Definisikan parameter grid untuk Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Grid Search): {grid_search.best_params_}\")\n",
    "best_rf_grid = grid_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "grid_search_score = best_rf_grid.score(X_test, y_test)\n",
    "print(f\"Accuracy after Grid Search: {grid_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    " \n",
    "# Definisikan ruang pencarian untuk Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': np.linspace(100, 500, 5, dtype=int),\n",
    "    'max_depth': np.linspace(10, 50, 5, dtype=int),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=20, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "best_rf_random = random_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "random_search_score = best_rf_random.score(X_test, y_test)\n",
    "print(f\"Accuracy after Random Search: {random_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    " \n",
    "# Definisikan ruang pencarian untuk Bayesian Optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "bayes_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Bayesian Optimization): {bayes_search.best_params_}\")\n",
    "best_rf_bayes = bayes_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "bayes_search_score = best_rf_bayes.score(X_test, y_test)\n",
    "print(f\"Accuracy after Bayesian Optimization: {bayes_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1g6EPSSWxjcQ"
   },
   "outputs": [],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UJNcVP--n7S"
   },
   "outputs": [],
   "source": [
    "# Menyimpan Model hasil tuning\n",
    "# import joblib\n",
    "# joblib.dump(__, 'tuning_classification.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hs4Xp4OiGEk"
   },
   "source": [
    "End of Code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (new-main-ds)",
   "language": "python",
   "name": "new-main-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
